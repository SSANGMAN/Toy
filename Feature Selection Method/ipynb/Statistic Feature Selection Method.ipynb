{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [How to Choose a Feature Selection Method For Machine Learning](https://machinelearningmastery.com/feature-selection-with-real-and-categorical-data/)\n",
    "\n",
    "\n",
    "\n",
    "Feature Selection은 예측 모델을 개발할 때 입력 변수 수를 줄이는 과정이다.\n",
    "\n",
    "입력 변수의 수를 줄임으로써 모델링의 계산 비용을 절감하고 경우에 따라 모델의 성능을 향상시키는 것이 바람직하다.\n",
    "\n",
    "통계학 기반 Feature Selection 방법에는 각 입력 변수와 목표 변수 사이의 관계를 평가하고 목표 변수와 가장 강력한 관계를 갖는 입력 변수를 선택한다. 입력 변수와 출력 변수 의 데이터 유형에 따라 다르다. 이 포스트에서는 각기 다른 입력 변수와 출력 변수의 유형에 따른 필터 기반 Feature Selection 방법에 대해 소개한다.\n",
    "\n",
    "이 포스트를 통해 다음과 같은 사실을 알 수 있다.\n",
    "\n",
    "- Feature Selection 기법에는 크게 Supervised Learning, Unsupervised Learning 두 가지 유형이 존재한다.\n",
    "- 필터 기반 Feature Selection 방법은 통계적 방법을 사용하여 가장 관련성이 높은 feature를 선택하기 위해 필터링할 수 있는 입력 변수 사이의 <b>상관관계</b>나 <b>의존성</b>을 점수화한다.\n",
    "- Feature Selection에 대한 통계적 측정은 입력 변수의 데이터 유형과 목표 변수에 기반하여 신중히 선택해야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "이 포스트는 총 4개의 파트로 나뉜다.\n",
    "\n",
    "1. Feature Selection 방법\n",
    "\n",
    "2. 통계학 기반 필터 Feature Selection 방법\n",
    "    - 수치형 입력, 수치형 출력\n",
    "    - 수치형 입력, 카테고리 출력\n",
    "    - 카테고리 입력, 수치형 출력\n",
    "    - 카테고리 입력, 카테고리 출력\n",
    "\n",
    "3. Feature Selection과 관련된 Tip과 Trick\n",
    "    - 상관관계 통계량\n",
    "    - 선택 방법\n",
    "    - 변수 변환\n",
    "    - 최고의 방법\n",
    "    \n",
    "4. 예제\n",
    "    - 회귀 문제에서 Feature Selection\n",
    "    - 분류 문제에서 Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변수 선택 방법\n",
    "\n",
    "변수 선택은 목표 변수를 예측하기 위해 모델에 가장 유용하다고 생각되는 입력 변수의 수를 줄이기 위한 것이다.\n",
    "\n",
    "<blockquote>변수 선택은 주로 모델에 불필요한 정보 또는 중복되는 입력 변수를 제거하는 데 초점을 맞춘다.</blockquote>\n",
    "- Page 488, Applied Predictive Modeling, 2013.\n",
    "\n",
    "일부 예측 모델링 문제는 모델의 개발 및 훈련을 지연시키는 변수가 많고 시스템 메모리가 많이 필요할 때다.또한 목표 변수와 관련이 없는 입력 변수를 포함하면 일부 모델의 성능이 저하될 수 있다.\n",
    "\n",
    "<blockquote> 많은 모형, 특히 회귀 기울기와 절편에 기초한 모델은 모델의 모든 항에 대한 모수를 추정할 것이다. 이 때문에 불필요한 정보를 담은 변수의 존재는 예측의 불확실성을 더하고 모델의 전체적인 효과를 감소시킬 수 있다.</blockquote>\n",
    "- Page 488, Applied Predictive Modeling, 2013.\n",
    "\n",
    "변수 선택 방법은 Supervised Learning과 Unsupervised Learning에서 아이디어를 얻을 수 있다.\n",
    "\n",
    "<blockquote> 변수 선택에 있어서 중요한 구분 방법은 Supervised Learning과 Unsupervised Learning이다. 입력 변수를 제거하는 동안 결과가 무시되면 이 방법은 Unsupervised Learning이다.</blockquote>\n",
    "- Page 488, Applied Predictive Modeling, 2013.\n",
    "\n",
    "이 차이는 목표 변수를 기준으로 변수를 선택했는지 여부와 관련이 있다. Unsupervised Learning 변수 선택은 상관관계를 이용하여 중복 변수를 제거하는 방법 등 목표 변수를 무시한다. 반면, Supervised Learning 변수 선택은 관계 없는 변수를 제거하는 방법과 같이 목표 변수를 사용한다.\n",
    "\n",
    "또 다른 방법으로는 <b>Wrapper</b>와 <b>Filter</b> 방법이 존재한다. 이 방법들은 변수 선택을 위해 사용되는 매커니즘 중 고려할 수 있는 Supervised Learning 방법이다.\n",
    "\n",
    "Wrapper 방법은 입력 변수들의 하위 집합이 서로 다른 많은 모델을 생성하고 성능 지표에 따라 최상의 성능을 보이는 변수를 선택한다. 이러한 방법은 계산상 비용이 많이 들 수 있지만 어떤 변수 형태에서도 사용이 가능하다. <b>RFE(Recursive Feautre Elimination)</b>는 Wrapper 방법 중 하나이다.\n",
    "\n",
    "<blockquote> Wrapper 방법은 입력 변수를 추가 및 제거하여 모델의 성능을 최대화하는 최적의 조합을 찾는 절차를 사용하고 여러 모델을 평가한다.</blockquote>\n",
    "— Page 490, Applied Predictive Modeling, 2013.\n",
    "\n",
    "Filter 방법은 통계적 기법을 사용하여 각 입력 변수와 목표 변수 사이의 관계를 평가하며, 평가한 점수는 모델에 사용될 입력 변수 필터링 기준으로 사용된다.\n",
    "\n",
    "<blockquote>Filter 방법은 예측 모델 외부의 입력 변수간 관련성을 평가하고 이후 일부 기준(평가 점수)를 통과한 입력 변수만 모델화 한다.</blockquote>\n",
    "— Page 490, Applied Predictive Modeling, 2013.\n",
    "\n",
    "마지막으로, 모델 학습의 일환으로 변수 선택을 자동으로 수행하는 머신러닝 알고리즘이 존재한다. 이러한 기법을 모델에 intrinsic(내장된) 변수 선택 방법이라고 할 수 있다.\n",
    "\n",
    "<blockquote> 일부 모델은 내장된 변수 선택을 포함하며, 이는 모델의 정확도를 극대화 하는 데 도움이 되는 입력 변수만 포함함을 의미한다. 이러한 경우 모델은 어떤 데이터가 가장 적합한지 선택할 수 있다.</blockquote>\n",
    "— Page 28, Applied Predictive Modeling, 2013.\n",
    "\n",
    "intrinsic 변수 선택 방법을 갖춘 알고리즘은 RandomForest와 같은 앙상블 및 의사결정나무 모델과 Lasso와 같은 규제화된 회귀 모델이 포함된다.\n",
    "\n",
    "<blockquote> 일부 모델은 예측에 유용하지 않은 정보를 가진 입력 변수들로부터 내성이 존재한다. 예를 들어, 트리 및 규칙 기반 모델, Lasso는 본질적으로 변수 선택을 수행한다.</blockquote>\n",
    "— Page 487, Applied Predictive Modeling, 2013.\n",
    "\n",
    "변수 선택은 예측에 불필요한 정보를 제거함으로써 차원 축소 기법과도 관련이 있다. 반면, 변수 선택은 데이터에서 유지하거나 제거할 변수를 선택하는 반면, 차원 축소는 데이터의 투영(Projection)을 생성하여 완전히 새로운 변수를 생성하는 것이다.\n",
    "\n",
    "구구절절 설명했지만, 변수 선택법은 다음과 같이 요약할 수 있다.\n",
    "\n",
    "- 변수 선택(Feature Selection): 주어진 데이터로부터 입력 변수의 하위 집합을 선택\n",
    "    - Unsupervised Learning: 목표 변수를 사용하지 않는다.(중복되는 변수를 제거한다.)\n",
    "        - Corrleation: 상관관계가 강한 입력 변수를 제거\n",
    "    - Supervised Learning: 목표 변수를 사용한다.(관련 없는 변수를 제거한다.)\n",
    "        - Wrapper: 최고의 성능을 내는 변수들에 대한 하위 집합을 선택\n",
    "            - RFE(Recursive Feature Elimination\n",
    "        - Filter: 목표 변수와 관계를 기준으로 변수의 하위 집합 선택\n",
    "            - 통계적 방법(Statistical Method)\n",
    "            - 변수 중요도(Feature Importance) 방법\n",
    "        - Intrinsic: 모델 훈련 과정에서 자동으로 변수 선택을 진행하는 알고리즘\n",
    "            - 의사결정나무\n",
    "            - Lasso 회귀\n",
    "            - Random Forest\n",
    "            \n",
    "- 차원 축소: 입력 데이터를 저차원 변수 공간에 투영\n",
    "\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/11/Overview-of-Feature-Selection-Techniques3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 통계학 기반 필터 Feature Selection 방법\n",
    "\n",
    "Filter기반 변수 선택법은 입력 변수와 출력 변수 사이의 상관관계를 통계적 측정하는 것이 일반적이다.\n",
    "\n",
    "통계적 측정을 이용한 변수 선택은 데이터의 유형에 크게 의존한다.\n",
    "\n",
    "공통 데이터 유형에는 수치형, 범주형이 포함되지만, 수치형 변수는 정수 및 실수, 범주형 변수는 부울, 순서형 또는 명목형 변수로 더욱 세분화될 수 있다.\n",
    "\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/Overview-of-Data-Variable-Types2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수의 데이터 유형에 대해 더 많이 알수록, Filter 기반의 변수 선택 방법에 대한 적절한 통계적 측정을 선택하는 것이 더 쉽다.\n",
    "\n",
    "이 챕터에서는 입력 및 출력 두 가지 주요 변수 유형의 광범위한 범주를 고려한다.\n",
    "\n",
    "입력 변수는 모델에 대한 입력으로 제공되는 변수들이다. 변수 선택에서 크기를 줄이기 원하는 것은 입력 변수 그룹이다. 목표 변수는 종종 반응 변수라고 불리는 모델이 예측하려는 변수다.\n",
    "\n",
    "목표 변수의 유형은 일반적으로 수행중인 예측 모델링 문제의 유형을 나타낸다. 예를 들어, 수치형 목표 변수는 회귀 예측 모델링 문제를 나타내고, 범주형 목표 변수는 분류 예측 모델링 문제를 나타낸다.\n",
    "\n",
    "- <strong>수치형 출력</strong>: 회귀 예측 모델링 문제\n",
    "- <strong>범주형 출력</strong>: 분류 예측 모델링 문제\n",
    "\n",
    "Filter 기반 변수 선택에 사용되는 통계적 척도는 일반적으로 목표 변수를 사용하여 한 번에 하나의 입력 변수를 계산한다. 이 방법은 <strong>일변량 통계적 측정</strong>이라고 부른다. 이는 입력 변수 간의 상호작용이 Filtering 과정에서 고려되지 않음을 의미한다.\n",
    "\n",
    "<blockquote> 이러한 기법들은 대부분 일변량인데, 이는 각 입력 변수를 개별적으로 평가한다는 것을 의미한다. 이 경우 상관된 입력 변수가 존재하면 중요하지만 중복된 입력 변수를 선택하는 문제가 발생할 수 있다. 그 결과 너무 많은 입력 변수가 선택되어 다중공선성 문제가 발생할 수 있다.</blockquote>\n",
    "— Page 499, Applied Predictive Modeling, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 그림을 통해 Filter 기반 변수 선택에 사용할 수 있는 몇 가지 일변량 통계적 측정을 확인할 수 있다.\n",
    "<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/11/How-to-Choose-Feature-Selection-Methods-For-Machine-Learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 수치형 변수 입력, 수치형 변수 출력\n",
    "일반적인 수치형 변수에 대한 회귀 예측 모델링 문제다.\n",
    "\n",
    "가장 일반적인 기법은 선형 상관관계에 대한 Pearson Correlation Coefficient나 비선형 상관관계에 대한 순위 기반 방법과 같은 상관 계수를 사용하는 것이다.\n",
    "- Pearson's correlation coefficient(linear).\n",
    "- Spearman's rank coefficient(nonlinear).\n",
    "\n",
    "## 수치형 변수 입력, 범주형 변수 출력\n",
    "이 문제는 수치형 입력 변수에 대한 분류 예측 모델링 문제다. 분류 문제의 가장 일반적인 예로 볼 수 있다.\n",
    "\n",
    "가장 일반적인 기법은 상관관계에 기반한 것이지만, 이 경우에는 목표 변수가 범주형 변수라는 것에 유의해야한다.\n",
    "\n",
    "- ANOVA correlation coefficient(linear).\n",
    "- Kendall's rank coefficient (nonlinear).\n",
    "\n",
    "Kendall은 범주형 변수가 순서형이라고 가정하는 방법이다.\n",
    "\n",
    "## 범주형 변수 입력, 수치형 변수 출력\n",
    "범주형 변수 입력에 대한 회귀 예측 모델링 문제다. 이 문제는 회귀 문제의 특수한 경우이며, 비교적 자주 마주치지 않는 문제다.\n",
    "\n",
    "그럼에도 불구하고, 수치형 변수 입력과 범주형 변수 출력 방법을 사용할 수 있지만, 반대로도 사용할 수 있다.\n",
    "\n",
    "## 범주형 변수 입력, 범주형 변수 출력\n",
    "범주형 입력 변수에 대한 분류 예측 모델링 문제다.\n",
    "\n",
    "범주형 데이터에 대한 가장 일반적인 상관 계수는 Chi-Squared 검정이다. 정보 이론 상호 정보(information gain)를 이용할 수 있다.\n",
    "\n",
    "- Chi-Squared test\n",
    "- Mutual Information\n",
    "\n",
    "사실, Mutual Information은 범주형 데이터와 수치형 데이터 모두에 유용한 것으로 입증된 강력한 방법이다. 즉, 데이터 유형에 구애받지 않는다.\n",
    "\n",
    "# Feature Selection과 관련된 Tip과 Trick\n",
    "이 챕터에서는 Filter 기반 변수 선택법을 사용할 때 몇 가지 추가 고려사항에 대해 알아본다.\n",
    "\n",
    "## 상관관계 통계량 (Correlation Statistics)\n",
    "Scikit-learn 라이브러리는 대부분의 유용한 통계적 측정을 제공한다.\n",
    "\n",
    "예시는 다음과 같다.\n",
    "- Pearson's Correlation Coefficieint: f_regression()\n",
    "- ANOVA: f_classif()\n",
    "- Chi-Squared: chi2()\n",
    "- Mutual Information: mutual_info_classif() and mutual_info_regression()\n",
    "\n",
    "또한, Scipy 라이브러리는 Kendall's tau(kendalltau)와 Spearman's rank correlation (spearmanr)과 같은 더 많은 통계적 측정을 구현한다.\n",
    "\n",
    "## 선택 방법\n",
    "또한, 목표 변수와 함께 각 입력 변수에 대한 통계량이 계산된 후 Scikit-learn 라이브러리는 다양한 Filtering 방법을 제공한다.  \n",
    "가장 인기 있는 두 가지 방법은 다음과 같다.\n",
    "\n",
    "- 상위 k개 변수들을 선택: SelectBest\n",
    "- 상위 백분위수에 대한 변수들을 선택: SelectPercentile\n",
    "\n",
    "이 게시물의 저자는 SelectBest를 종종 사용한다고 한다.\n",
    "\n",
    "## 변수 변환\n",
    "또 다른 통계적 방법으로 접근하는 방법은 변수를 변환시키는 것이다. \n",
    "\n",
    "예를 들어, 범주형 변수를 순서형으로 변환하여 흥미로운 결과가 나오는지 확인할 수 있다. 또한, 수치형 변수를 이산형으로 만들어 사용할 수 있으며 이러한 변수를 범주형 변수로 사용할 수 있을 것이다.\n",
    "\n",
    "Pearson's Correlation과 같이 정규 분포를 가정하는 선형 변수 선택법을 사용할 경우, 비선형 분포를 따르는 변수를 변환하여 결과를 비교할 수있다.\n",
    "\n",
    "## 최고의 방법\n",
    "변수 선택에서 최고의 방법이란 존재하지 않는다. '최고의 변수 선택 방법이 무엇일까?'라는 질문은 마치 '최고의 기계학습 알고리즘은 무엇일까?'라는 질문과 같은 말이다. \n",
    "\n",
    "따라서, 특정한 문제에 가장 잘 맞는 변수 선택법을 찾아야한다. 반복적인 실험을 통해 문제에 가장 잘 맞는 것을 발견하는 것이 중요하다.\n",
    "\n",
    "다양한 통계적 측정을 통해 선택한 변수의 하위 집합에 맞는 다양한 모델을 사용해보고 문제에 가장 적합한 모델을 찾는 것이 중요하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 예제\n",
    "이제, 예제 코드를 통해 직접 변수 선택을 수행해본다. \n",
    "\n",
    "## 회귀 문제에서 변수 선택 (수치형 입력, 수치형 출력)\n",
    "이 절에서는 수치형 변수 입력 및 수치형 출력으로서 회귀 문제에 대한 변수 선택법에 대해 설명한다.\n",
    "\n",
    "간단한 회귀 문제를 적용하기 위해 `make_regression`을 이용해 100개 변수로 구성된 100개의 샘플을 생성한다. 그 후, `f_recription`함수를 통해 Pearson's Correlation을 사용하여 변수를 선택한다. 변수 선택법을 적용한 입력 변수와 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:29:00.349430Z",
     "start_time": "2020-08-16T10:29:00.341407Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:29:00.489496Z",
     "start_time": "2020-08-16T10:29:00.465856Z"
    }
   },
   "outputs": [],
   "source": [
    "X,y = make_regression(n_samples = 100, n_features = 100, n_informative = 10, random_state = 42)\n",
    "X_train = X[:70, :]\n",
    "y_train = y[:70]\n",
    "\n",
    "X_test = X[70:, :]\n",
    "y_test = y[70:]\n",
    "\n",
    "fs = SelectKBest(score_func = f_regression, k = 10)\n",
    "X_train_selected = fs.fit_transform(X_train,y_train)\n",
    "X_test_selected = fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "변수를 선택하기 이전과 이후에 대한 모델 성능의 변화는 다음과 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:29:01.022848Z",
     "start_time": "2020-08-16T10:29:00.996708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  72.87857805664436\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression()\n",
    "reg.fit(X_train,y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test)\n",
    "print(\"RMSE = \", mean_squared_error(y_test, y_pred)**0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:29:01.478550Z",
     "start_time": "2020-08-16T10:29:01.455379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE =  57.05654293398997\n"
     ]
    }
   ],
   "source": [
    "reg.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred = reg.predict(X_test_selected)\n",
    "print(\"RMSE = \", mean_squared_error(y_test, y_pred)**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 문제에서 변수 선택(수치형 입력, 범주형 출력)\n",
    "이 절에서는 수치형 입력 변수와 범주형 출력 변수인 분류 문제에 대한 변수 선택에 대해 설명한다.\n",
    "\n",
    "`make_classification`을 사용하여 간단한 분류 적용 문제에 대한 데이터를 생성한다. 그 후, `f_classif` 함수를 사용하여 분산 분석(ANOVA) F 검정을 사용하여 변수를 선택한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:35:12.832656Z",
     "start_time": "2020-08-16T10:35:12.809298Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:34:04.163949Z",
     "start_time": "2020-08-16T10:34:04.141203Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 100, n_features = 20, n_informative = 2)\n",
    "X_train = X[:70, :]\n",
    "y_train = y[:70]\n",
    "\n",
    "X_test = X[70:, :]\n",
    "y_test = y[70:]\n",
    "\n",
    "fs = SelectKBest(score_func = f_regression, k = 5)\n",
    "X_train_selected = fs.fit_transform(X_train,y_train)\n",
    "X_test_selected = fs.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:35:43.523969Z",
     "start_time": "2020-08-16T10:35:43.498715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-16T10:36:13.797280Z",
     "start_time": "2020-08-16T10:36:13.776143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_selected, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test_selected)\n",
    "print(\"Accuracy = \", accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.708px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
